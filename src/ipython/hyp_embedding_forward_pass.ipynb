{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arctanh(x):\n",
    "    return tf.log(tf.divide(1+x,1-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise all of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inner_prod(r_in, r_out, theta_in, theta_out):\n",
    "    cosine = tf.cos(theta_in - theta_out)\n",
    "    radius = tf.multiply(arctanh(r_in), arctanh(r_out))\n",
    "    return 4 * tf.multiply(cosine, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_dot(u,v):\n",
    "    return tf.tensordot(u,v,1) - 2*tf.multiply(u[0],v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exponential(base, tangent):\n",
    "    \"\"\"\n",
    "    Compute the exponential of `tangent` from the point `base`.\n",
    "    \"\"\"\n",
    "    #tangent = tangent.copy()\n",
    "    norm = tf.sqrt(tf.maximum(minkowski_dot(tangent, tangent), 0))\n",
    "    if norm == 0:\n",
    "        return base\n",
    "    tangent /= norm\n",
    "    return tf.cosh(norm) * base + tf.sinh(norm) * tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensor_inner_prod(r_example, r_sample, theta_example, theta_sample):\n",
    "    r1 = arctanh(r_example)\n",
    "    r2 = arctanh(r_sample)\n",
    "    radius_term = r1[:, None] + r2[None, :]\n",
    "    cos_term = theta_example[:, None] - theta_sample[None, :]\n",
    "    return tf.squeeze(4* tf.multiply(cos_term, radius_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nce_loss(true_logits, sampled_logits):\n",
    "        true_xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.ones_like(true_logits), logits=true_logits)\n",
    "        sampled_xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.zeros_like(sampled_logits), logits=sampled_logits)\n",
    "        nce_loss_tensor = (tf.reduce_sum(true_xent) +\n",
    "                           tf.reduce_sum(sampled_xent)) / 2\n",
    "        return nce_loss_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_dist(u, v):\n",
    "    \"\"\"\n",
    "    The distance between two points in Minkowski space\n",
    "    :param u:\n",
    "    :param v:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return tf.acosh(-minkowski_dot(u, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_onto_tangent_space(hyperboloid_point, minkowski_tangent):\n",
    "    \"\"\"\n",
    "    project gradients in the ambiant space onto the tangent space\n",
    "    :param hyperboloid_point:\n",
    "    :param minkowski_tangent:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return minkowski_tangent + minkowski_dot(hyperboloid_point, minkowski_tangent) * hyperboloid_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_map(base, tangent):\n",
    "    \"\"\"\n",
    "    Compute the exponential of the `tangent` vector from the point `base`.\n",
    "    \"\"\"\n",
    "    # tangent = tangent.copy()\n",
    "    norm = tf.sqrt(tf.maximum(minkowski_dot(tangent, tangent), 0))\n",
    "    if norm == 0:\n",
    "        return base\n",
    "    tangent /= norm\n",
    "    return tf.cosh(norm) * base + tf.sinh(norm) * tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_tensor_dot(u, v):\n",
    "    \"\"\"\n",
    "    Minkowski dot product is the same as the Euclidean dot product, but the first element squared is subtracted\n",
    "    :param u: a tensor of shape (#examples, dims)\n",
    "    :param v: a tensor of shape (#examples, dims)\n",
    "    :return: a scalar dot product\n",
    "    \"\"\"\n",
    "    assert u.shape == v.shape, 'minkowski dot product not define for different shape tensors'\n",
    "    try:\n",
    "        temp = np.eye(u.shape[1])\n",
    "    except IndexError:\n",
    "        temp = np.eye(u.shape)\n",
    "    temp[0, 0] = -1.\n",
    "    T = tf.constant(temp, dtype=u.dtype)\n",
    "    # make the first column of v negative\n",
    "    v_neg = tf.matmul(v, T)\n",
    "    return tf.reduce_sum(tf.multiply(u, v_neg), 1, keep_dims=True)  # keep dims for broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairwise_minkowski_dot(u, v):\n",
    "    \"\"\"\n",
    "    creates a matrix of minkowski dot products M(i,j) = u[i,:]*v[j,:]\n",
    "    :param examples: first set of vectors of shape (ndata1, ndim)\n",
    "    :param samples: second set of vectors of shape (ndata2, ndim)\n",
    "    :return: A numpy array of shape (ndata1, ndata2) of pairwise squared distances\n",
    "    \"\"\"\n",
    "    try:\n",
    "        temp = np.eye(u.shape[1])\n",
    "    except IndexError:\n",
    "        temp = np.eye(u.shape)\n",
    "    temp[0, 0] = -1.\n",
    "    T = tf.constant(temp, dtype=u.dtype)\n",
    "    # make the first column of v negative\n",
    "    v_neg = tf.matmul(v, T)\n",
    "    return tf.matmul(u, v_neg, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3. -5.]\n",
      " [ 4.  6.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,0],[0,1]])\n",
    "y = np.array([[3,4],[5,6]])\n",
    "tx = tf.Variable(x, dtype=tf.float32)\n",
    "ty = tf.Variable(y, dtype=tf.float32)\n",
    "retval = np.array([[-3,-5],[4,6]])\n",
    "temp = np.eye(y.shape[1])\n",
    "temp[0, 0] = -1.\n",
    "T = tf.constant(temp, dtype=ty.dtype)\n",
    "ty_neg = tf.matmul(ty, T)\n",
    "z = tf.matmul(tx,ty_neg, transpose_b=True)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensor_exp_map(vars, indices, tangent_grads):\n",
    "    \"\"\"\n",
    "    Map vectors in the tangent space of the hyperboloid points back onto the hyperboloid\n",
    "    :param hyperboloid_points: a tensor of points on the hyperboloid of shape (#examples, #dims)\n",
    "    :param tangent_grads: a tensor of gradients on the tangent spaces of the hyperboloid_points of shape (#examples, #dims)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # todo do we need to normalise the gradients?\n",
    "    hyperboloid_points = tf.nn.embedding_lookup(vars, indices)\n",
    "    norms = tf.sqrt(tf.maximum(minkowski_tensor_dot(tangent_grads, tangent_grads), 0))\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    nonzero_flags = tf.squeeze(tf.not_equal(norms, zero))\n",
    "#     nonzero_indices = tf.squeeze(tf.where(nonzero_flags))\n",
    "    nonzero_indices = tf.boolean_mask(indices, nonzero_flags)\n",
    "    nonzero_norms = tf.boolean_mask(norms, nonzero_flags)\n",
    "    updated_grads = tf.boolean_mask(tangent_grads, tf.squeeze(nonzero_flags))\n",
    "    updated_points = tf.boolean_mask(hyperboloid_points, nonzero_flags)\n",
    "    # if norms == 0:\n",
    "    #     return hyperboloid_points\n",
    "    normed_grads = tf.divide(updated_grads, nonzero_norms)\n",
    "    updates = tf.multiply(tf.cosh(nonzero_norms), updated_points) + tf.multiply(tf.sinh(nonzero_norms), normed_grads)\n",
    "    return tf.scatter_update(vars, nonzero_indices, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.08988699,  0.23446067],\n",
      "       [ 0.08988699,  0.23446067]], dtype=float32), array([[ 0.21654591],\n",
      "       [ 0.21654591]], dtype=float32), array([[ 0.41509435,  1.08272958],\n",
      "       [ 0.41509435,  1.08272958]], dtype=float32), array([[False, False],\n",
      "       [False, False]], dtype=bool), array([[ 0.41509435,  1.08272958],\n",
      "       [ 0.41509435,  1.08272958]], dtype=float32), array([[ 1.19880569,  0.6611622 ],\n",
      "       [ 1.19880569,  0.6611622 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.constant([[0., 1.], [0., 1.]])\n",
    "# p1 = tf.constant([[2.31737995, 2.09051466],[2.31737995, 2.09051466]])\n",
    "# p1 = tf.constant([[1.,0.],[1,0.]])\n",
    "# p1 = tf.constant([[ 1.02006674,  0.20133601],[ 1.02006674,  0.20133601]])\n",
    "p1 = tf.constant([[ 1.08272946,  0.41509438],[ 1.08272946,  0.41509438]])\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "raw_tangent_grads = project_tensors_onto_tangent_space(p1, g1)\n",
    "tangent_grads = 0.2*raw_tangent_grads\n",
    "norms = tf.sqrt(tf.maximum(minkowski_tensor_dot(tangent_grads, tangent_grads), 0))\n",
    "normed_grads = tf.divide(tangent_grads, norms) \n",
    "values_to_replace = tf.logical_or(tf.is_nan(normed_grads), tf.is_inf(normed_grads))\n",
    "safe_grads = tf.where(values_to_replace, tf.ones_like(normed_grads), normed_grads)\n",
    "updates = tf.multiply(tf.cosh(norms), p1) + tf.multiply(tf.sinh(norms), safe_grads)\n",
    "print(sess.run([tangent_grads, norms, normed_grads, values_to_replace, safe_grads, updates]))\n",
    "# print(sess.run(project_tensors_onto_tangent_space(p1, g1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   1.54308069e+00   3.76219559e+00   1.00676622e+01\n",
      "   2.73082333e+01   7.42099457e+01   2.01715637e+02   5.48317017e+02\n",
      "   1.49047913e+03   4.05154199e+03   1.10132334e+04   2.99370703e+04\n",
      "   8.13773984e+04   2.21206703e+05   6.01302125e+05   1.63450862e+06\n",
      "   4.44305550e+06   1.20774760e+07   3.28299840e+07   8.92411520e+07\n",
      "   2.42582592e+08   6.59407872e+08   1.79245645e+09   4.87240192e+09\n",
      "   1.32445614e+10   3.60024515e+10   9.78648023e+10   2.66024124e+11\n",
      "   7.23128549e+11   1.96566712e+12   5.34323711e+12   1.45244249e+13\n",
      "   3.94814785e+13   1.07321787e+14   2.91730855e+14   7.93006723e+14\n",
      "   2.15561577e+15   5.85957127e+15   1.59279657e+16   4.32967020e+16\n",
      "   1.17692635e+17   3.19921737e+17   8.69637488e+17   2.36391976e+18\n",
      "   6.42579994e+18   1.74671353e+19   4.74805977e+19   1.29065645e+20\n",
      "   3.50836779e+20   9.53673320e+20   2.59235273e+21   7.04674518e+21\n",
      "   1.91550409e+22   5.20687949e+22   1.41537661e+23   3.84739274e+23\n",
      "   1.04582972e+24   2.84286001e+24   7.72769446e+24   2.10060523e+25\n",
      "   5.71003698e+25   1.55214889e+26   4.21917841e+26   1.14689156e+27\n",
      "   3.11757442e+27   8.47444603e+27   2.30359327e+28   6.26181593e+28\n",
      "   1.70213809e+29   4.62689081e+29   1.25771935e+30   3.41883557e+30\n",
      "   9.29335853e+30   2.52619678e+31   6.86691481e+31   1.86662092e+32\n",
      "   5.07400209e+32   1.37925677e+33   3.74920849e+33   1.01914051e+34\n",
      "   2.77031124e+34   7.53048681e+34   2.04699843e+35   5.56431864e+35\n",
      "   1.51253867e+36   4.11150651e+36   1.11762326e+37   3.03801517e+37\n",
      "   8.25818133e+37   2.24480639e+38              inf              inf\n",
      "              inf              inf              inf              inf\n",
      "              inf              inf              inf              inf]\n",
      "[  0.00000000e+00   1.17520118e+00   3.62686038e+00   1.00178747e+01\n",
      "   2.72899170e+01   7.42032089e+01   2.01713150e+02   5.48316101e+02\n",
      "   1.49047888e+03   4.05154199e+03   1.10132324e+04   2.99370703e+04\n",
      "   8.13773984e+04   2.21206703e+05   6.01302125e+05   1.63450862e+06\n",
      "   4.44305550e+06   1.20774760e+07   3.28299840e+07   8.92411520e+07\n",
      "   2.42582592e+08   6.59407872e+08   1.79245645e+09   4.87240192e+09\n",
      "   1.32445614e+10   3.60024515e+10   9.78648023e+10   2.66024124e+11\n",
      "   7.23128549e+11   1.96566712e+12   5.34323711e+12   1.45244249e+13\n",
      "   3.94814785e+13   1.07321787e+14   2.91730855e+14   7.93006723e+14\n",
      "   2.15561577e+15   5.85957127e+15   1.59279657e+16   4.32967020e+16\n",
      "   1.17692635e+17   3.19921737e+17   8.69637488e+17   2.36391976e+18\n",
      "   6.42579994e+18   1.74671353e+19   4.74805977e+19   1.29065645e+20\n",
      "   3.50836779e+20   9.53673320e+20   2.59235273e+21   7.04674518e+21\n",
      "   1.91550409e+22   5.20687949e+22   1.41537661e+23   3.84739274e+23\n",
      "   1.04582972e+24   2.84286001e+24   7.72769446e+24   2.10060523e+25\n",
      "   5.71003698e+25   1.55214889e+26   4.21917841e+26   1.14689156e+27\n",
      "   3.11757442e+27   8.47444603e+27   2.30359327e+28   6.26181593e+28\n",
      "   1.70213809e+29   4.62689081e+29   1.25771935e+30   3.41883557e+30\n",
      "   9.29335853e+30   2.52619678e+31   6.86691481e+31   1.86662092e+32\n",
      "   5.07400209e+32   1.37925677e+33   3.74920849e+33   1.01914051e+34\n",
      "   2.77031124e+34   7.53048681e+34   2.04699843e+35   5.56431864e+35\n",
      "   1.51253867e+36   4.11150651e+36   1.11762326e+37   3.03801517e+37\n",
      "   8.25818133e+37   2.24480639e+38              inf              inf\n",
      "              inf              inf              inf              inf\n",
      "              inf              inf              inf              inf]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "t = tf.constant(np.arange(100), dtype=tf.float32)\n",
    "print(sess.run(tf.cosh(t)))\n",
    "print(sess.run(tf.sinh(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 0. -1.]\n",
      " [ 0.  2.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.constant([[0., 1.], [0., -1.], [0., 2.], [1., 1.]])\n",
    "norms = tf.constant([0., 1., 1., 0.], shape=(4, 1))\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "normed_g = tf.divide(g1, norms)\n",
    "values_to_replace = tf.logical_or(tf.is_nan(normed_g),tf.is_inf(normed_g))\n",
    "g2 = tf.where(values_to_replace, tf.ones_like(normed_g), normed_g)\n",
    "print(sess.run(g2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99999976]\n",
      " [-0.99999976]\n",
      " [-0.99999714]\n",
      " [-1.        ]]\n"
     ]
    }
   ],
   "source": [
    "input_points = np.array([[1., 0.], [1., 0.],[4.,5.], [1., 0.], [1., 0.]])\n",
    "p1 = tf.Variable(input_points, dtype=tf.float32)  # this the minima of the hyperboloid\n",
    "indices = tf.constant([0,1,3,4])\n",
    "g1 = tf.constant([[0., 1.], [0., -1.], [0., 2.], [0., 0.]])\n",
    "retval1 = np.array([[-1.], [-1.], [-1.], [-1.]])\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "# here the tangent space is x=1\n",
    "new_vars = tensor_exp_map(p1, indices, g1)\n",
    "em1 = tf.nn.embedding_lookup(new_vars,indices)\n",
    "# check that the points are on the hyperboloid\n",
    "norms = sess.run(minkowski_tensor_dot(em1, em1))\n",
    "print(norms)\n",
    "assert np.array_equal(np.around(norms, 3), retval1)\n",
    "em1 = sess.run(em1)\n",
    "new_vars = sess.run(new_vars)\n",
    "np_new_vars = np.array(new_vars)\n",
    "assert np.array_equal(np_new_vars[2,:],input_points[2,:])\n",
    "assert np.array_equal(np_new_vars[4,:],input_points[4,:])\n",
    "assert em1[0, 0] == em1[1, 0]\n",
    "assert em1[0, 1] == -em1[1, 1]\n",
    "assert em1[2, 0] > em1[0, 0]\n",
    "assert em1[2, 1] > em1[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True False]\n",
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "norms = tf.constant([1.,0.,1.,0.])\n",
    "zero = tf.constant(0, dtype=tf.float32)\n",
    "nonzero_flags = tf.squeeze(tf.not_equal(norms, zero))\n",
    "nonzero_indices = tf.squeeze(tf.where(nonzero_flags))\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(nonzero_flags))\n",
    "print(sess.run(nonzero_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_tensors_onto_tangent_space(hyperboloid_points, ambient_gradients):\n",
    "    \"\"\"\n",
    "    project gradients in the ambiant space onto the tangent space\n",
    "    :param hyperboloid_point: A point on the hyperboloid\n",
    "    :param ambient_gradient: The gradient to project\n",
    "    :return: gradients in the tangent spaces of the hyperboloid points\n",
    "    \"\"\"\n",
    "    return ambient_gradients + tf.multiply(minkowski_tensor_dot(hyperboloid_points, ambient_gradients),\n",
    "                                           hyperboloid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_grads(grad):\n",
    "    \"\"\"\n",
    "    multiply by the inverse of the Minkowski metric tensor g = diag[-1, 1,1 ... 1] to make the first element of each\n",
    "    grad vector negative\n",
    "    :param grad: grad matrix of shape (n_vars, embedding_dim)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = np.eye(grad.shape[1])\n",
    "    x[0, 0] = -1.\n",
    "    T = tf.constant(x, dtype=grad.dtype)\n",
    "    return tf.matmul(grad, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rsgd(grads, vecs, lr=0.1):\n",
    "    \"\"\"\n",
    "    Perform the Riemannian gradient descent operation by\n",
    "    1/ Transforming gradients using the Minkowski metric tensor\n",
    "    2/ Projecting onto the tangent space\n",
    "    3/ Applying the exponential map\n",
    "    :param grads:\n",
    "    :param var:\n",
    "    :param lr:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    minkowski_grads = transform_grads(grads)\n",
    "    tangent_grads = project_tensors_onto_tangent_space(vecs, minkowski_grads)\n",
    "    return tensor_exp_map(vecs, lr * tangent_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_vector_dot(u, v):\n",
    "    \"\"\"\n",
    "        Minkowski dot product is the same as the Euclidean dot product, but the first element squared is subtracted\n",
    "        :param u: a vector\n",
    "        :param v: a vector\n",
    "        :return: a scalar dot product\n",
    "        \"\"\"\n",
    "    assert u.shape == v.shape, 'minkowski dot product not define for different shape vectors'\n",
    "    # assert that the vectors have only 1d.\n",
    "    # todo this currently fails because exp_map returns tensors with shape = None\n",
    "    # assert u.get_shape().ndims == 1, 'applied minkowski_vector_dot to a tensor. Try using minkowski_tensor_dot'\n",
    "\n",
    "    return tf.tensordot(u, v, 1) - 2 * tf.multiply(u[0], v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_onto_tangent_space(hyperboloid_point, ambient_gradient):\n",
    "    \"\"\"\n",
    "    project gradients in the ambiant space onto the tangent space\n",
    "    :param hyperboloid_point: A point on the hyperboloid\n",
    "    :param ambient_gradient: The gradient to project\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return ambient_gradient + minkowski_vector_dot(hyperboloid_point, ambient_gradient) * hyperboloid_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "point = tf.Variable([3.76219535,3.62686038])\n",
    "g1 = tf.constant([-3., 2.])\n",
    "# minkowski_grads = transform_grads(g1)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(project_onto_tangent_space(point, g1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = tf.Variable([[1., 0.], [1., 0.], [1., 0.], [1., 0.]])  # this the minima of the hyperboloid\n",
    "grads = tf.Variable([[1., 1.], [2., -1.], [3., 2.], [4., 0.]])\n",
    "retval1 = np.array([[-1.], [-1.], [-1.], [-1.]])\n",
    "sess = tf.Session()\n",
    "lr = 0.1\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "vals = []\n",
    "for i in range(3):\n",
    "    vals.append(sess.run(points))\n",
    "    print(vals[i])\n",
    "    print(sess.run(minkowski_tensor_dot(vals[i], vals[i])))\n",
    "#     print(sess.run(points))\n",
    "    points = rsgd(grads, points)\n",
    "#     vals.append(points)\n",
    "    # check that the points are on the hyperboloid\n",
    "#     norms = sess.run(minkowski_tensor_dot(points, points))\n",
    "#     print(norms)\n",
    "#     try:\n",
    "#         assert np.array_equal(np.around(norms, 3), retval1)\n",
    "#     except AssertionError:\n",
    "#         print(sess.run(points))\n",
    "print(sess.run(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def circ_sample():\n",
    "    from matplotlib.pyplot import scatter\n",
    "    # radius of the circle\n",
    "    circle_r = 1\n",
    "    # center of the circle (x, y)\n",
    "    circle_x = 0\n",
    "    circle_y = 0\n",
    "\n",
    "    # random angle\n",
    "    alpha = 2 * math.pi * np.random.rand(1000)\n",
    "    # random radius\n",
    "    r = circle_r * np.sqrt(np.random.rand(1000))\n",
    "    # calculating coordinates\n",
    "    x = r * np.cos(alpha) + circle_x\n",
    "    y = r * np.sin(alpha) + circle_y\n",
    "#     scatter(x,y)\n",
    "    retval = np.concatenate((x,y), axis=0)\n",
    "    print(retval)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_hyperboloid_points(poincare_pts):\n",
    "    \"\"\"\n",
    "    Post: result.shape[1] == poincare_pts.shape[1] + 1\n",
    "    \"\"\"\n",
    "    norm_sqd = (poincare_pts ** 2).sum(axis=1)\n",
    "    N = poincare_pts.shape[1]\n",
    "    result = np.zeros((poincare_pts.shape[0], N + 1), dtype=np.float64)\n",
    "    result[:, 1:] = (2. / (1 - norm_sqd))[:, np.newaxis] * poincare_pts\n",
    "    result[:, 0] = (1 + norm_sqd) / (1 - norm_sqd)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_hyperboloid_points(vocab_size, embedding_size, init_width):\n",
    "    \"\"\"\n",
    "    Post: result.shape[1] == poincare_pts.shape[1] + 1\n",
    "    \"\"\"\n",
    "    poincare_pts = np.random.uniform(-init_width, init_width, (vocab_size, embedding_size))\n",
    "    norm_sqd = (poincare_pts ** 2).sum(axis=1)\n",
    "    # the hyperboloid has one extra ambient dimension\n",
    "    result = np.zeros((poincare_pts.shape[0], embedding_size + 1), dtype=np.float64)\n",
    "    result[:, 1:] = (2. / (1 - norm_sqd))[:, np.newaxis] * poincare_pts\n",
    "    result[:, 0] = (1 + norm_sqd) / (1 - norm_sqd)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward(examples):\n",
    "    emb = tf.Variable(to_hyperboloid_points(4, 2, 1),\n",
    "                                       name=\"emb\", dtype=tf.float32)\n",
    "    \n",
    "    return tf.nn.embedding_lookup(emb, examples)\n",
    "\n",
    "sess = tf.Session()\n",
    "lr = 0.1\n",
    "sess.run(init)\n",
    "examples = forward([1,2])\n",
    "init = tf.global_variables_initializer()\n",
    "print(examples.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_distance(x, y):\n",
    "    \"\"\"\n",
    "    The distance between two vectors\n",
    "    :param x: shape (1, ndims)\n",
    "    :param y: shape (1,ndims)\n",
    "    :return: a scalar hyperbolic distance\n",
    "    \"\"\"\n",
    "    norm_square = tf.square(tf.norm(x - y, axis=0))\n",
    "    print norm_square\n",
    "    denom1 = 1 - tf.square(tf.norm(x, axis=0))\n",
    "    print denom1\n",
    "    denom2 = 1 - tf.square(tf.norm(y, axis=0))\n",
    "    print denom2\n",
    "    arg = 1 + 2 * norm_square / (denom1 * denom2)\n",
    "    print arg\n",
    "    return tf.acosh(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_logits(example, label, sample, true_b, sample_b):\n",
    "    true_logits = tf_distance(example, label) + true_b\n",
    "    sampled_logits = tf_distance(example, sample) + sample_b\n",
    "    return true_logits, sampled_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('emb shape: ', TensorShape([Dimension(2), Dimension(2)]))\n",
      "('sample w shape: ', TensorShape([Dimension(2), Dimension(2)]))\n",
      "Tensor(\"Square_6:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"sub_8:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"sub_9:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"add_52:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"Square_9:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"sub_11:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"sub_12:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"add_54:0\", shape=(2,), dtype=float32)\n",
      "original vectors:  [array([[-0.08015664, -0.03832245],\n",
      "       [ 0.00510602,  0.07676881]], dtype=float32), array([[-0.03569365,  0.09615657],\n",
      "       [-0.03569365,  0.09615657]], dtype=float32)]\n",
      "emb grads are:  [(IndexedSlicesValue(values=array([[-0.1547108 ,  0.18855031],\n",
      "       [-0.52542841,  0.59112638]], dtype=float32), indices=array([1, 2], dtype=int32), dense_shape=array([4, 2], dtype=int32)), array([[ 0.03230792, -0.03401699],\n",
      "       [-0.08015664, -0.03832245],\n",
      "       [ 0.00510602,  0.07676881],\n",
      "       [ 0.04951311,  0.02841205]], dtype=float32))]\n",
      "sm_w_t grads are:  [(IndexedSlicesValue(values=array([[-0.34602442, -0.43472701],\n",
      "       [ 0.31946567, -0.06761152],\n",
      "       [ 0.5002647 ,  0.24187784],\n",
      "       [ 0.20870665, -0.53353995]], dtype=float32), indices=array([2, 2, 1, 3], dtype=int32), dense_shape=array([4, 2], dtype=int32)), array([[-0.02628662,  0.08874855],\n",
      "       [-0.00383961,  0.03000958],\n",
      "       [-0.03569365,  0.09615657],\n",
      "       [ 0.03668339, -0.07375183]], dtype=float32))]\n",
      "updated vectors:  [array([[-0.06468556, -0.05717748],\n",
      "       [ 0.05764886,  0.01765617]], dtype=float32), array([[-0.03303777,  0.14639042],\n",
      "       [-0.03303777,  0.14639042]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 2\n",
    "vocab_size = 4\n",
    "emb = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -0.1, 0.1))\n",
    "sm_w_t = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -0.1, 0.1))\n",
    "# sm_w_t = tf.Variable(tf.zeros([vocab_size, embedding_size]))\n",
    "sm_b = tf.Variable(tf.zeros([vocab_size]))\n",
    "\n",
    "examples = tf.Variable([1,2])\n",
    "labels = tf.Variable([2,2])\n",
    "sampled_ids = tf.Variable([1,3])\n",
    "\n",
    "example_emb = tf.nn.embedding_lookup(emb, examples)\n",
    "# Weights for labels: [batch_size, emb_dim]\n",
    "true_w = tf.nn.embedding_lookup(sm_w_t, labels)\n",
    "# Biases for labels: [batch_size, 1]\n",
    "true_b = tf.nn.embedding_lookup(sm_b, labels)\n",
    "sampled_w = tf.nn.embedding_lookup(sm_w_t, sampled_ids)\n",
    "print('emb shape: ', example_emb.shape)\n",
    "print('sample w shape: ', sampled_w.shape)\n",
    "# Biases for sampled ids: [num_sampled, 1]\n",
    "sampled_b = tf.nn.embedding_lookup(sm_b, sampled_ids)\n",
    "true_logits, sampled_logits = get_logits(example_emb, true_w, sampled_w, true_b, sampled_b)\n",
    "loss = nce_loss(true_logits, sampled_logits)\n",
    "opt = tf.train.GradientDescentOptimizer(0.1)\n",
    "emb_grad = opt.compute_gradients(loss, [emb])\n",
    "sm_w_t_grad = opt.compute_gradients(loss, [sm_w_t])\n",
    "grads = emb_grad + sm_w_t_grad\n",
    "apply_grad = opt.apply_gradients(grads)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print 'original vectors: ', sess.run([example_emb, true_w])\n",
    "    print 'emb grads are: ', sess.run(emb_grad)\n",
    "    print 'sm_w_t grads are: ', sess.run(sm_w_t_grad)\n",
    "    sess.run(apply_grad)\n",
    "    print 'updated vectors: ', sess.run([example_emb, true_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = tf.Variable([1,2])\n",
    "labels_matrix = tf.reshape(\n",
    "            tf.cast(labels,\n",
    "                    dtype=tf.int64),\n",
    "            [2, 1])\n",
    "\n",
    "# Negative sampling.\n",
    "sampled_ids, _, _ = (tf.nn.fixed_unigram_candidate_sampler(\n",
    "    true_classes=labels_matrix,\n",
    "    num_true=1,\n",
    "    num_sampled=5,\n",
    "    unique=True,  # set to True if all the samples need to be unique\n",
    "    range_max=5,\n",
    "    distortion=0.75,\n",
    "    unigrams=[1,1,1,1,1]))\n",
    "                     \n",
    "print(sampled_ids.shape)\n",
    "print(sampled_ids)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(sampled_ids))\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = {'indices':[1,2],'values':[4,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "grads = namedtuple('grads', 'values indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads.values = [1,2]\n",
    "grads.indices = [3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2]])\n",
    "np.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arccosh(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   1.]\n",
      " [  1.   4.]\n",
      " [  4.   9.]\n",
      " [  0.  16.]]\n",
      "[[ 1.73205078]\n",
      " [ 2.44948959]\n",
      " [ 3.74165726]\n",
      " [ 4.12310553]]\n",
      "[[ 1.73205078  1.          1.        ]\n",
      " [ 2.44948959 -1.          2.        ]\n",
      " [ 3.74165726  2.          3.        ]\n",
      " [ 4.12310553  0.          4.        ]]\n",
      "[[-1.        ]\n",
      " [-0.99999905]\n",
      " [-0.99999905]\n",
      " [-1.        ]]\n"
     ]
    }
   ],
   "source": [
    "input_value = tf.Variable([[1., 1., 1.], [2., -1., 2.], [3., 2., 3.], [4., 0., 4.]])\n",
    "kept_values = input_value[:,1:]\n",
    "norm_square = tf.square(kept_values)\n",
    "new_vals = tf.expand_dims(tf.sqrt(tf.reduce_sum(norm_square, axis=1)+1),axis=1)\n",
    "tensor = tf.concat([new_vals, kept_values], axis=1)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(norm_square))\n",
    "print(sess.run(new_vals))\n",
    "print(sess.run(tensor))\n",
    "print(sess.run(minkowski_tensor_dot(tensor,tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
