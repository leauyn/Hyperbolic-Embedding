{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arctanh(x):\n",
    "    return tf.log(tf.divide(1+x,1-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise all of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inner_prod(r_in, r_out, theta_in, theta_out):\n",
    "    cosine = tf.cos(theta_in - theta_out)\n",
    "    radius = tf.multiply(arctanh(r_in), arctanh(r_out))\n",
    "    return 4 * tf.multiply(cosine, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_dot(u,v):\n",
    "    return tf.tensordot(u,v,1) - 2*tf.multiply(u[0],v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exponential(base, tangent):\n",
    "    \"\"\"\n",
    "    Compute the exponential of `tangent` from the point `base`.\n",
    "    \"\"\"\n",
    "    #tangent = tangent.copy()\n",
    "    norm = tf.sqrt(tf.maximum(minkowski_dot(tangent, tangent), 0))\n",
    "    if norm == 0:\n",
    "        return base\n",
    "    tangent /= norm\n",
    "    return tf.cosh(norm) * base + tf.sinh(norm) * tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensor_inner_prod(r_example, r_sample, theta_example, theta_sample):\n",
    "    r1 = arctanh(r_example)\n",
    "    r2 = arctanh(r_sample)\n",
    "    radius_term = r1[:, None] + r2[None, :]\n",
    "    cos_term = theta_example[:, None] - theta_sample[None, :]\n",
    "    return tf.squeeze(4* tf.multiply(cos_term, radius_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nce_loss(true_logits, sampled_logits):\n",
    "        true_xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.ones_like(true_logits), logits=true_logits)\n",
    "        sampled_xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.zeros_like(sampled_logits), logits=sampled_logits)\n",
    "        nce_loss_tensor = (tf.reduce_sum(true_xent) +\n",
    "                           tf.reduce_sum(sampled_xent)) / 2\n",
    "        return nce_loss_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_dist(u, v):\n",
    "    \"\"\"\n",
    "    The distance between two points in Minkowski space\n",
    "    :param u:\n",
    "    :param v:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return tf.acosh(-minkowski_dot(u, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_onto_tangent_space(hyperboloid_point, minkowski_tangent):\n",
    "    \"\"\"\n",
    "    project gradients in the ambiant space onto the tangent space\n",
    "    :param hyperboloid_point:\n",
    "    :param minkowski_tangent:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return minkowski_tangent + minkowski_dot(hyperboloid_point, minkowski_tangent) * hyperboloid_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_map(base, tangent):\n",
    "    \"\"\"\n",
    "    Compute the exponential of the `tangent` vector from the point `base`.\n",
    "    \"\"\"\n",
    "    # tangent = tangent.copy()\n",
    "    norm = tf.sqrt(tf.maximum(minkowski_dot(tangent, tangent), 0))\n",
    "    if norm == 0:\n",
    "        return base\n",
    "    tangent /= norm\n",
    "    return tf.cosh(norm) * base + tf.sinh(norm) * tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_tensor_dot(u, v):\n",
    "    \"\"\"\n",
    "    Minkowski dot product is the same as the Euclidean dot product, but the first element squared is subtracted\n",
    "    :param u: a tensor of shape (#examples, dims)\n",
    "    :param v: a tensor of shape (#examples, dims)\n",
    "    :return: a scalar dot product\n",
    "    \"\"\"\n",
    "    assert u.shape == v.shape, 'minkowski dot product not define for different shape tensors'\n",
    "    try:\n",
    "        temp = np.eye(u.shape[1])\n",
    "    except IndexError:\n",
    "        temp = np.eye(u.shape)\n",
    "    temp[0, 0] = -1.\n",
    "    T = tf.constant(temp, dtype=u.dtype)\n",
    "    # make the first column of v negative\n",
    "    v_neg = tf.matmul(v, T)\n",
    "    return tf.reduce_sum(tf.multiply(u, v_neg), 1, keep_dims=True)  # keep dims for broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensor_exp_map(hyperboloid_points, tangent_grads):\n",
    "    \"\"\"\n",
    "    Map vectors in the tangent space of the hyperboloid points back onto the hyperboloid\n",
    "    :param hyperboloid_points: a tensor of points on the hyperboloid of shape (#examples, #dims)\n",
    "    :param tangent_grads: a tensor of gradients on the tangent spaces of the hyperboloid_points of shape (#examples, #dims)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # todo do we need to normalise the gradients?\n",
    "    norms = tf.sqrt(tf.maximum(minkowski_tensor_dot(tangent_grads, tangent_grads), 0))\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    nonzero_flags = tf.squeeze(tf.not_equal(norms, zero))\n",
    "    nonzero_indices = tf.squeeze(tf.where(nonzero_flags))\n",
    "    nonzero_norms = tf.boolean_mask(norms, nonzero_flags)\n",
    "    updated_grads = tf.boolean_mask(tangent_grads, tf.squeeze(nonzero_flags))\n",
    "    updated_points = tf.boolean_mask(hyperboloid_points, nonzero_flags)\n",
    "    # if norms == 0:\n",
    "    #     return hyperboloid_points\n",
    "    normed_grads = tf.divide(updated_grads, nonzero_norms)\n",
    "    updates = tf.multiply(tf.cosh(nonzero_norms), updated_points) + tf.multiply(tf.sinh(nonzero_norms), normed_grads)\n",
    "    return tf.scatter_update(hyperboloid_points, nonzero_indices, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_tensors_onto_tangent_space(hyperboloid_points, ambient_gradients):\n",
    "    \"\"\"\n",
    "    project gradients in the ambiant space onto the tangent space\n",
    "    :param hyperboloid_point: A point on the hyperboloid\n",
    "    :param ambient_gradient: The gradient to project\n",
    "    :return: gradients in the tangent spaces of the hyperboloid points\n",
    "    \"\"\"\n",
    "    return ambient_gradients + tf.multiply(minkowski_tensor_dot(hyperboloid_points, ambient_gradients),\n",
    "                                           hyperboloid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_grads(grad):\n",
    "    \"\"\"\n",
    "    multiply by the inverse of the Minkowski metric tensor g = diag[-1, 1,1 ... 1] to make the first element of each\n",
    "    grad vector negative\n",
    "    :param grad: grad matrix of shape (n_vars, embedding_dim)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = np.eye(grad.shape[1])\n",
    "    x[0, 0] = -1.\n",
    "    T = tf.constant(x, dtype=grad.dtype)\n",
    "    return tf.matmul(grad, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rsgd(grads, vecs, lr=0.1):\n",
    "    \"\"\"\n",
    "    Perform the Riemannian gradient descent operation by\n",
    "    1/ Transforming gradients using the Minkowski metric tensor\n",
    "    2/ Projecting onto the tangent space\n",
    "    3/ Applying the exponential map\n",
    "    :param grads:\n",
    "    :param var:\n",
    "    :param lr:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    minkowski_grads = transform_grads(grads)\n",
    "    tangent_grads = project_tensors_onto_tangent_space(vecs, minkowski_grads)\n",
    "    return tensor_exp_map(vecs, lr * tangent_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.]\n",
      " [-2. -1.]\n",
      " [-3.  2.]\n",
      " [-4.  0.]]\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.constant([[1., 1.], [2., -1.], [3., 2.], [4., 0.]])\n",
    "retval1 = np.array([[-1., 1.], [-2., -1.], [-3., 2.], [-4., 0.]])\n",
    "transformed_grads = transform_grads(g1)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "tgs = sess.run(transformed_grads)\n",
    "print(tgs)\n",
    "assert np.array_equal(tgs, retval1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('minkowski grads', array([[-1.,  1.],\n",
      "       [-2., -1.],\n",
      "       [-3.,  2.],\n",
      "       [-4.,  0.]], dtype=float32))\n",
      "('tangent space grads', array([[  3.19452763,   4.19452763],\n",
      "       [  4.57562494,  -6.00795794],\n",
      "       [ 66.75225067,  69.24310303],\n",
      "       [  0.        ,   0.        ]], dtype=float32))\n",
      "('new points', array([[  2.06089172e+01,   2.05846424e+01],\n",
      "       [  6.67124863e+01,  -6.67050018e+01],\n",
      "       [  3.63710016e+08,   3.63710048e+08],\n",
      "       [  1.00000000e+00,   0.00000000e+00]], dtype=float32))\n",
      "[[ -9.99969482e-01]\n",
      " [ -9.98535156e-01]\n",
      " [  2.57698038e+10]\n",
      " [ -1.00000000e+00]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-402-37b77ea5cdb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminkowski_tensor_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretval1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p1 = tf.Variable([[1., 0.], [1., 0.], [1., 0.], [1., 0.]])  # this the minima of the hyperboloid\n",
    "p2 = tf.Variable([[ 1.54308057, 1.17520118],[ 1.54308057,-1.17520118],[ 3.76219535,3.62686038],[ 1.,0.]])\n",
    "g1 = tf.constant([[1., 1.], [2., -1.], [3., 2.], [4., 0.]])\n",
    "retval1 = np.array([[-1.], [-1.], [-1.], [-1.]])\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "# here the tangent space is x=1\n",
    "# print(sess.run(rsgd(g1, p1)))\n",
    "minkowski_grads = transform_grads(g1)\n",
    "tangent_grads = project_tensors_onto_tangent_space(p2, minkowski_grads)\n",
    "pnew = tensor_exp_map(p2, tangent_grads)\n",
    "# # check that the points are on the hyperboloid\n",
    "# # print(sess.run(p2))\n",
    "print('minkowski grads', sess.run(minkowski_grads))\n",
    "print('tangent space grads', sess.run(tangent_grads))\n",
    "new_points = sess.run(pnew)\n",
    "print('new points', new_points)\n",
    "# norms = sess.run(minkowski_tensor_dot(pnew, pnew))\n",
    "norms = sess.run(minkowski_tensor_dot(new_points, new_points))\n",
    "print(norms)\n",
    "assert np.array_equal(np.around(norms, 3), retval1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_vector_dot(u, v):\n",
    "    \"\"\"\n",
    "        Minkowski dot product is the same as the Euclidean dot product, but the first element squared is subtracted\n",
    "        :param u: a vector\n",
    "        :param v: a vector\n",
    "        :return: a scalar dot product\n",
    "        \"\"\"\n",
    "    assert u.shape == v.shape, 'minkowski dot product not define for different shape vectors'\n",
    "    # assert that the vectors have only 1d.\n",
    "    # todo this currently fails because exp_map returns tensors with shape = None\n",
    "    # assert u.get_shape().ndims == 1, 'applied minkowski_vector_dot to a tensor. Try using minkowski_tensor_dot'\n",
    "\n",
    "    return tf.tensordot(u, v, 1) - 2 * tf.multiply(u[0], v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_onto_tangent_space(hyperboloid_point, ambient_gradient):\n",
    "    \"\"\"\n",
    "    project gradients in the ambiant space onto the tangent space\n",
    "    :param hyperboloid_point: A point on the hyperboloid\n",
    "    :param ambient_gradient: The gradient to project\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return ambient_gradient + minkowski_vector_dot(hyperboloid_point, ambient_gradient) * hyperboloid_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "point = tf.Variable([3.76219535,3.62686038])\n",
    "g1 = tf.constant([-3., 2.])\n",
    "# minkowski_grads = transform_grads(g1)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(project_onto_tangent_space(point, g1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = tf.Variable([[1., 0.], [1., 0.], [1., 0.], [1., 0.]])  # this the minima of the hyperboloid\n",
    "grads = tf.Variable([[1., 1.], [2., -1.], [3., 2.], [4., 0.]])\n",
    "retval1 = np.array([[-1.], [-1.], [-1.], [-1.]])\n",
    "sess = tf.Session()\n",
    "lr = 0.1\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "vals = []\n",
    "for i in range(3):\n",
    "    vals.append(sess.run(points))\n",
    "    print(vals[i])\n",
    "    print(sess.run(minkowski_tensor_dot(vals[i], vals[i])))\n",
    "#     print(sess.run(points))\n",
    "    points = rsgd(grads, points)\n",
    "#     vals.append(points)\n",
    "    # check that the points are on the hyperboloid\n",
    "#     norms = sess.run(minkowski_tensor_dot(points, points))\n",
    "#     print(norms)\n",
    "#     try:\n",
    "#         assert np.array_equal(np.around(norms, 3), retval1)\n",
    "#     except AssertionError:\n",
    "#         print(sess.run(points))\n",
    "print(sess.run(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def circ_sample():\n",
    "    from matplotlib.pyplot import scatter\n",
    "    # radius of the circle\n",
    "    circle_r = 1\n",
    "    # center of the circle (x, y)\n",
    "    circle_x = 0\n",
    "    circle_y = 0\n",
    "\n",
    "    # random angle\n",
    "    alpha = 2 * math.pi * np.random.rand(1000)\n",
    "    # random radius\n",
    "    r = circle_r * np.sqrt(np.random.rand(1000))\n",
    "    # calculating coordinates\n",
    "    x = r * np.cos(alpha) + circle_x\n",
    "    y = r * np.sin(alpha) + circle_y\n",
    "#     scatter(x,y)\n",
    "    retval = np.concatenate((x,y), axis=0)\n",
    "    print(retval)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_hyperboloid_points(poincare_pts):\n",
    "    \"\"\"\n",
    "    Post: result.shape[1] == poincare_pts.shape[1] + 1\n",
    "    \"\"\"\n",
    "    norm_sqd = (poincare_pts ** 2).sum(axis=1)\n",
    "    N = poincare_pts.shape[1]\n",
    "    result = np.zeros((poincare_pts.shape[0], N + 1), dtype=np.float64)\n",
    "    result[:, 1:] = (2. / (1 - norm_sqd))[:, np.newaxis] * poincare_pts\n",
    "    result[:, 0] = (1 + norm_sqd) / (1 - norm_sqd)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "lr = 0.1\n",
    "tens = tf.Variable(hyp_points)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "assert np.array_equal(np.around(sess.run(minkowski_tensor_dot(tens, tens)),3), np.array(100 * [[-1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_width = 1\n",
    "vocab_size = 2\n",
    "embedding_size = 3\n",
    "poincare_pts = np.random.uniform(-init_width, init_width, (vocab_size, embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08277187, -0.95914259, -0.50169398],\n",
       "       [ 0.24245755, -0.74738919, -0.59993851]])"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poincare_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
