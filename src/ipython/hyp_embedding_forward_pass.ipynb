{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arctanh(x):\n",
    "    return tf.log(tf.divide(1+x,1-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise all of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inner_prod(r_in, r_out, theta_in, theta_out):\n",
    "    cosine = tf.cos(theta_in - theta_out)\n",
    "    radius = tf.multiply(arctanh(r_in), arctanh(r_out))\n",
    "    return 4 * tf.multiply(cosine, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_dot(u,v):\n",
    "    return tf.tensordot(u,v,1) - 2*tf.multiply(u[0],v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exponential(base, tangent):\n",
    "    \"\"\"\n",
    "    Compute the exponential of `tangent` from the point `base`.\n",
    "    \"\"\"\n",
    "    #tangent = tangent.copy()\n",
    "    norm = tf.sqrt(tf.maximum(minkowski_dot(tangent, tangent), 0))\n",
    "    if norm == 0:\n",
    "        return base\n",
    "    tangent /= norm\n",
    "    return tf.cosh(norm) * base + tf.sinh(norm) * tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensor_inner_prod(r_example, r_sample, theta_example, theta_sample):\n",
    "    r1 = arctanh(r_example)\n",
    "    r2 = arctanh(r_sample)\n",
    "    radius_term = r1[:, None] + r2[None, :]\n",
    "    cos_term = theta_example[:, None] - theta_sample[None, :]\n",
    "    return tf.squeeze(4* tf.multiply(cos_term, radius_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nce_loss(true_logits, sampled_logits):\n",
    "        true_xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.ones_like(true_logits), logits=true_logits)\n",
    "        sampled_xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.zeros_like(sampled_logits), logits=sampled_logits)\n",
    "        nce_loss_tensor = (tf.reduce_sum(true_xent) +\n",
    "                           tf.reduce_sum(sampled_xent)) / 2\n",
    "        return nce_loss_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_dist(u, v):\n",
    "    \"\"\"\n",
    "    The distance between two points in Minkowski space\n",
    "    :param u:\n",
    "    :param v:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return tf.acosh(-minkowski_dot(u, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_onto_tangent_space(hyperboloid_point, minkowski_tangent):\n",
    "    \"\"\"\n",
    "    project gradients in the ambiant space onto the tangent space\n",
    "    :param hyperboloid_point:\n",
    "    :param minkowski_tangent:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return minkowski_tangent + minkowski_dot(hyperboloid_point, minkowski_tangent) * hyperboloid_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_map(base, tangent):\n",
    "    \"\"\"\n",
    "    Compute the exponential of the `tangent` vector from the point `base`.\n",
    "    \"\"\"\n",
    "    # tangent = tangent.copy()\n",
    "    norm = tf.sqrt(tf.maximum(minkowski_dot(tangent, tangent), 0))\n",
    "    if norm == 0:\n",
    "        return base\n",
    "    tangent /= norm\n",
    "    return tf.cosh(norm) * base + tf.sinh(norm) * tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_tensor_dot(u, v):\n",
    "    \"\"\"\n",
    "    Minkowski dot product is the same as the Euclidean dot product, but the first element squared is subtracted\n",
    "    :param u: a tensor of shape (#examples, dims)\n",
    "    :param v: a tensor of shape (#examples, dims)\n",
    "    :return: a scalar dot product\n",
    "    \"\"\"\n",
    "    assert u.shape == v.shape, 'minkowski dot product not define for different shape tensors'\n",
    "    try:\n",
    "        temp = np.eye(u.shape[1])\n",
    "    except IndexError:\n",
    "        temp = np.eye(u.shape)\n",
    "    temp[0, 0] = -1.\n",
    "    T = tf.constant(temp, dtype=u.dtype)\n",
    "    # make the first column of v negative\n",
    "    v_neg = tf.matmul(v, T)\n",
    "    return tf.reduce_sum(tf.multiply(u, v_neg), 1, keep_dims=True)  # keep dims for broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensor_exp_map(hyperboloid_points, tangent_grads):\n",
    "    \"\"\"\n",
    "    Map vectors in the tangent space of the hyperboloid points back onto the hyperboloid\n",
    "    :param hyperboloid_points: a tensor of points on the hyperboloid of shape (#examples, #dims)\n",
    "    :param tangent_grads: a tensor of gradients on the tangent spaces of the hyperboloid_points of shape (#examples, #dims)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # todo do we need to normalise the gradients?\n",
    "    norms = tf.sqrt(tf.maximum(minkowski_tensor_dot(tangent_grads, tangent_grads), 0))\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    nonzero_flags = tf.squeeze(tf.not_equal(norms, zero))\n",
    "    nonzero_indices = tf.squeeze(tf.where(nonzero_flags))\n",
    "    nonzero_norms = tf.boolean_mask(norms, nonzero_flags)\n",
    "    updated_grads = tf.boolean_mask(tangent_grads, tf.squeeze(nonzero_flags))\n",
    "    updated_points = tf.boolean_mask(hyperboloid_points, nonzero_flags)\n",
    "    # if norms == 0:\n",
    "    #     return hyperboloid_points\n",
    "    normed_grads = tf.divide(updated_grads, nonzero_norms)\n",
    "    updates = tf.multiply(tf.cosh(nonzero_norms), updated_points) + tf.multiply(tf.sinh(nonzero_norms), normed_grads)\n",
    "    return tf.scatter_update(hyperboloid_points, nonzero_indices, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_tensors_onto_tangent_space(hyperboloid_points, ambient_gradients):\n",
    "    \"\"\"\n",
    "    project gradients in the ambiant space onto the tangent space\n",
    "    :param hyperboloid_point: A point on the hyperboloid\n",
    "    :param ambient_gradient: The gradient to project\n",
    "    :return: gradients in the tangent spaces of the hyperboloid points\n",
    "    \"\"\"\n",
    "    return ambient_gradients + tf.multiply(minkowski_tensor_dot(hyperboloid_points, ambient_gradients),\n",
    "                                           hyperboloid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_grads(grad):\n",
    "    \"\"\"\n",
    "    multiply by the inverse of the Minkowski metric tensor g = diag[-1, 1,1 ... 1] to make the first element of each\n",
    "    grad vector negative\n",
    "    :param grad: grad matrix of shape (n_vars, embedding_dim)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = np.eye(grad.shape[1])\n",
    "    x[0, 0] = -1.\n",
    "    T = tf.constant(x, dtype=grad.dtype)\n",
    "    return tf.matmul(grad, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rsgd(grads, vecs, lr=0.1):\n",
    "    \"\"\"\n",
    "    Perform the Riemannian gradient descent operation by\n",
    "    1/ Transforming gradients using the Minkowski metric tensor\n",
    "    2/ Projecting onto the tangent space\n",
    "    3/ Applying the exponential map\n",
    "    :param grads:\n",
    "    :param var:\n",
    "    :param lr:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    minkowski_grads = transform_grads(grads)\n",
    "    tangent_grads = project_tensors_onto_tangent_space(vecs, minkowski_grads)\n",
    "    return tensor_exp_map(vecs, lr * tangent_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.]\n",
      " [-2. -1.]\n",
      " [-3.  2.]\n",
      " [-4.  0.]]\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.constant([[1., 1.], [2., -1.], [3., 2.], [4., 0.]])\n",
    "retval1 = np.array([[-1., 1.], [-2., -1.], [-3., 2.], [-4., 0.]])\n",
    "transformed_grads = transform_grads(g1)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "tgs = sess.run(transformed_grads)\n",
    "print(tgs)\n",
    "assert np.array_equal(tgs, retval1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('minkowski grads', array([[-1.,  1.],\n",
      "       [-2., -1.],\n",
      "       [-3.,  2.],\n",
      "       [-4.,  0.]], dtype=float32))\n",
      "('tangent space grads', array([[  3.19452763,   4.19452763],\n",
      "       [  4.57562494,  -6.00795794],\n",
      "       [ 66.75225067,  69.24310303],\n",
      "       [  0.        ,   0.        ]], dtype=float32))\n",
      "('new points', array([[  2.06089172e+01,   2.05846424e+01],\n",
      "       [  6.67124863e+01,  -6.67050018e+01],\n",
      "       [  3.63710016e+08,   3.63710048e+08],\n",
      "       [  1.00000000e+00,   0.00000000e+00]], dtype=float32))\n",
      "[[ -9.99969482e-01]\n",
      " [ -9.98535156e-01]\n",
      " [  2.57698038e+10]\n",
      " [ -1.00000000e+00]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-37b77ea5cdb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminkowski_tensor_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretval1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p1 = tf.Variable([[1., 0.], [1., 0.], [1., 0.], [1., 0.]])  # this the minima of the hyperboloid\n",
    "p2 = tf.Variable([[ 1.54308057, 1.17520118],[ 1.54308057,-1.17520118],[ 3.76219535,3.62686038],[ 1.,0.]])\n",
    "g1 = tf.constant([[1., 1.], [2., -1.], [3., 2.], [4., 0.]])\n",
    "retval1 = np.array([[-1.], [-1.], [-1.], [-1.]])\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "# here the tangent space is x=1\n",
    "# print(sess.run(rsgd(g1, p1)))\n",
    "minkowski_grads = transform_grads(g1)\n",
    "tangent_grads = project_tensors_onto_tangent_space(p2, minkowski_grads)\n",
    "pnew = tensor_exp_map(p2, tangent_grads)\n",
    "# # check that the points are on the hyperboloid\n",
    "# # print(sess.run(p2))\n",
    "print('minkowski grads', sess.run(minkowski_grads))\n",
    "print('tangent space grads', sess.run(tangent_grads))\n",
    "new_points = sess.run(pnew)\n",
    "print('new points', new_points)\n",
    "# norms = sess.run(minkowski_tensor_dot(pnew, pnew))\n",
    "norms = sess.run(minkowski_tensor_dot(new_points, new_points))\n",
    "print(norms)\n",
    "assert np.array_equal(np.around(norms, 3), retval1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minkowski_vector_dot(u, v):\n",
    "    \"\"\"\n",
    "        Minkowski dot product is the same as the Euclidean dot product, but the first element squared is subtracted\n",
    "        :param u: a vector\n",
    "        :param v: a vector\n",
    "        :return: a scalar dot product\n",
    "        \"\"\"\n",
    "    assert u.shape == v.shape, 'minkowski dot product not define for different shape vectors'\n",
    "    # assert that the vectors have only 1d.\n",
    "    # todo this currently fails because exp_map returns tensors with shape = None\n",
    "    # assert u.get_shape().ndims == 1, 'applied minkowski_vector_dot to a tensor. Try using minkowski_tensor_dot'\n",
    "\n",
    "    return tf.tensordot(u, v, 1) - 2 * tf.multiply(u[0], v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def project_onto_tangent_space(hyperboloid_point, ambient_gradient):\n",
    "    \"\"\"\n",
    "    project gradients in the ambiant space onto the tangent space\n",
    "    :param hyperboloid_point: A point on the hyperboloid\n",
    "    :param ambient_gradient: The gradient to project\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return ambient_gradient + minkowski_vector_dot(hyperboloid_point, ambient_gradient) * hyperboloid_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 66.75225067  69.24310303]\n"
     ]
    }
   ],
   "source": [
    "point = tf.Variable([3.76219535,3.62686038])\n",
    "g1 = tf.constant([-3., 2.])\n",
    "# minkowski_grads = transform_grads(g1)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(project_onto_tangent_space(point, g1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "[[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "[[ 1.00500417  0.10016676]\n",
      " [ 1.00500417 -0.10016676]\n",
      " [ 1.02006674  0.20133603]\n",
      " [ 1.          0.        ]]\n",
      "[[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "[[ 1.05628109  0.34019053]\n",
      " [ 1.06826913 -0.37576473]\n",
      " [ 1.36538982  0.92967153]\n",
      " [ 1.          0.        ]]\n",
      "[[-1.00000012]\n",
      " [-0.99999988]\n",
      " [-1.00000024]\n",
      " [-1.        ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([[ 1.,  0.],\n       [ 1.,  0.],\n       [ 1.,  0.],\n       [ 1.,  0.]], dtype=float32) has invalid type <type 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-da2247e67ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     except AssertionError:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         print(sess.run(points))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ben.chamberlain/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ben.chamberlain/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1109\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ben.chamberlain/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \"\"\"\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ben.chamberlain/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ben.chamberlain/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \"\"\"\n\u001b[1;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ben.chamberlain/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/Users/ben.chamberlain/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    272\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    273\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    275\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument array([[ 1.,  0.],\n       [ 1.,  0.],\n       [ 1.,  0.],\n       [ 1.,  0.]], dtype=float32) has invalid type <type 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "points = tf.Variable([[1., 0.], [1., 0.], [1., 0.], [1., 0.]])  # this the minima of the hyperboloid\n",
    "grads = tf.Variable([[1., 1.], [2., -1.], [3., 2.], [4., 0.]])\n",
    "retval1 = np.array([[-1.], [-1.], [-1.], [-1.]])\n",
    "sess = tf.Session()\n",
    "lr = 0.1\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "vals = []\n",
    "for i in range(3):\n",
    "    vals.append(sess.run(points))\n",
    "    print(vals[i])\n",
    "    print(sess.run(minkowski_tensor_dot(vals[i], vals[i])))\n",
    "#     print(sess.run(points))\n",
    "    points = rsgd(grads, points)\n",
    "#     vals.append(points)\n",
    "    # check that the points are on the hyperboloid\n",
    "#     norms = sess.run(minkowski_tensor_dot(points, points))\n",
    "#     print(norms)\n",
    "#     try:\n",
    "#         assert np.array_equal(np.around(norms, 3), retval1)\n",
    "#     except AssertionError:\n",
    "#         print(sess.run(points))\n",
    "print(sess.run(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def circ_sample():\n",
    "    from matplotlib.pyplot import scatter\n",
    "    # radius of the circle\n",
    "    circle_r = 1\n",
    "    # center of the circle (x, y)\n",
    "    circle_x = 0\n",
    "    circle_y = 0\n",
    "\n",
    "    # random angle\n",
    "    alpha = 2 * math.pi * np.random.rand(1000)\n",
    "    # random radius\n",
    "    r = circle_r * np.sqrt(np.random.rand(1000))\n",
    "    # calculating coordinates\n",
    "    x = r * np.cos(alpha) + circle_x\n",
    "    y = r * np.sin(alpha) + circle_y\n",
    "#     scatter(x,y)\n",
    "    retval = np.concatenate((x,y), axis=0)\n",
    "    print(retval)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_hyperboloid_points(poincare_pts):\n",
    "    \"\"\"\n",
    "    Post: result.shape[1] == poincare_pts.shape[1] + 1\n",
    "    \"\"\"\n",
    "    norm_sqd = (poincare_pts ** 2).sum(axis=1)\n",
    "    N = poincare_pts.shape[1]\n",
    "    result = np.zeros((poincare_pts.shape[0], N + 1), dtype=np.float64)\n",
    "    result[:, 1:] = (2. / (1 - norm_sqd))[:, np.newaxis] * poincare_pts\n",
    "    result[:, 0] = (1 + norm_sqd) / (1 - norm_sqd)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hyp_points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-098f043633a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hyp_points' is not defined"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "lr = 0.1\n",
    "tens = tf.Variable(hyp_points)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "assert np.array_equal(np.around(sess.run(minkowski_tensor_dot(tens, tens)),3), np.array(100 * [[-1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_width = 1\n",
    "vocab_size = 2\n",
    "embedding_size = 3\n",
    "poincare_pts = np.random.uniform(-init_width, init_width, (vocab_size, embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_hyperboloid_points(vocab_size, embedding_size, init_width):\n",
    "    \"\"\"\n",
    "    Post: result.shape[1] == poincare_pts.shape[1] + 1\n",
    "    \"\"\"\n",
    "    poincare_pts = np.random.uniform(-init_width, init_width, (vocab_size, embedding_size))\n",
    "    norm_sqd = (poincare_pts ** 2).sum(axis=1)\n",
    "    # the hyperboloid has one extra ambient dimension\n",
    "    result = np.zeros((poincare_pts.shape[0], embedding_size + 1), dtype=np.float64)\n",
    "    result[:, 1:] = (2. / (1 - norm_sqd))[:, np.newaxis] * poincare_pts\n",
    "    result[:, 0] = (1 + norm_sqd) / (1 - norm_sqd)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "def forward(examples):\n",
    "    emb = tf.Variable(to_hyperboloid_points(4, 2, 1),\n",
    "                                       name=\"emb\", dtype=tf.float32)\n",
    "    \n",
    "    return tf.nn.embedding_lookup(emb, examples)\n",
    "\n",
    "sess = tf.Session()\n",
    "lr = 0.1\n",
    "sess.run(init)\n",
    "examples = forward([1,2])\n",
    "init = tf.global_variables_initializer()\n",
    "print(examples.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_distance(x, y):\n",
    "    \"\"\"\n",
    "    The distance between two vectors\n",
    "    :param x: shape (1, ndims)\n",
    "    :param y: shape (1,ndims)\n",
    "    :return: a scalar hyperbolic distance\n",
    "    \"\"\"\n",
    "    norm_square = tf.square(tf.norm(x - y, axis=0))\n",
    "    print norm_square\n",
    "    denom1 = 1 - tf.square(tf.norm(x, axis=0))\n",
    "    print denom1\n",
    "    denom2 = 1 - tf.square(tf.norm(y, axis=0))\n",
    "    print denom2\n",
    "    arg = 1 + 2 * norm_square / (denom1 * denom2)\n",
    "    print arg\n",
    "    return tf.acosh(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_logits(example, label, sample, true_b, sample_b):\n",
    "    true_logits = tf_distance(example, label) + true_b\n",
    "    sampled_logits = tf_distance(example, sample) + sample_b\n",
    "    return true_logits, sampled_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_grads_vectors():\n",
    "    \"\"\"\n",
    "    tests the gradients of the pairwise and elementwise distance functions with 1 sample, 1 example and 1 label\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embedding_size = 2\n",
    "    vocab_size = 4\n",
    "    emb = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -0.1, 0.1))\n",
    "    sm_w_t = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -0.1, 0.1))\n",
    "    # sm_w_t = tf.Variable(tf.zeros([vocab_size, embedding_size]))\n",
    "    sm_b = tf.Variable(tf.zeros([vocab_size]))\n",
    "\n",
    "    examples = tf.Variable([1,2])\n",
    "    labels = tf.Variable([2,2])\n",
    "    sampled_ids = tf.Variable([1,3])\n",
    "\n",
    "    example_emb = tf.nn.embedding_lookup(emb, examples)\n",
    "    # Weights for labels: [batch_size, emb_dim]\n",
    "    true_w = tf.nn.embedding_lookup(sm_w_t, labels)\n",
    "    # Biases for labels: [batch_size, 1]\n",
    "    true_b = tf.nn.embedding_lookup(sm_b, labels)\n",
    "    sampled_w = tf.nn.embedding_lookup(sm_w_t, sampled_ids)\n",
    "    print('emb shape: ', example_emb.shape)\n",
    "    print('sample w shape: ', sampled_w.shape)\n",
    "    # Biases for sampled ids: [num_sampled, 1]\n",
    "    sampled_b = tf.nn.embedding_lookup(sm_b, sampled_ids)\n",
    "    true_logits, sampled_logits = get_logits(example_emb, true_w, sampled_w, true_b, sampled_b)\n",
    "    loss = nce_loss(true_logits, sampled_logits)\n",
    "    opt = tf.train.GradientDescentOptimizer(0.1)\n",
    "    emb_grad = opt.compute_gradients(loss, [emb])\n",
    "    sm_w_t_grad = opt.compute_gradients(loss, [sm_w_t])\n",
    "    grads = emb_grad + sm_w_t_grad\n",
    "    apply_grad = opt.apply_gradients(grads)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print 'original vectors: ', sess.run([example_emb, true_w])\n",
    "        print 'emb grads are: ', sess.run(emb_grad)\n",
    "        print 'sm_w_t grads are: ', sess.run(sm_w_t_grad)\n",
    "        sess.run(apply_grad)\n",
    "        print 'updated vectors: ', sess.run([example_emb, true_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('emb shape: ', TensorShape([Dimension(2), Dimension(2)]))\n",
      "('sample w shape: ', TensorShape([Dimension(2), Dimension(2)]))\n",
      "Tensor(\"Square:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"sub_2:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"sub_3:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"add_9:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"Square_3:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"sub_5:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"sub_6:0\", shape=(2,), dtype=float32)\n",
      "Tensor(\"add_11:0\", shape=(2,), dtype=float32)\n",
      "original vectors:  [array([[-0.07931326,  0.00481357],\n",
      "       [ 0.0957616 ,  0.00107229]], dtype=float32), array([[-0.09562647,  0.04233987],\n",
      "       [-0.09562647,  0.04233987]], dtype=float32)]\n",
      "emb grads are:  [(IndexedSlicesValue(values=array([[-0.57865351,  0.61299074],\n",
      "       [-0.17891437,  0.79511589]], dtype=float32), indices=array([1, 2], dtype=int32), dense_shape=array([4, 2], dtype=int32)), array([[-0.03485067, -0.08269012],\n",
      "       [-0.07931326,  0.00481357],\n",
      "       [ 0.0957616 ,  0.00107229],\n",
      "       [-0.05464559, -0.01024082]], dtype=float32))]\n",
      "sm_w_t grads are:  [(IndexedSlicesValue(values=array([[ 0.04181116, -0.3188175 ],\n",
      "       [ 0.40952271, -0.35049129],\n",
      "       [ 0.55104357, -0.29649469],\n",
      "       [-0.21750996, -0.44785726]], dtype=float32), indices=array([2, 2, 1, 3], dtype=int32), dense_shape=array([4, 2], dtype=int32)), array([[-0.06781726, -0.03996351],\n",
      "       [ 0.08386905, -0.0335886 ],\n",
      "       [-0.09562647,  0.04233987],\n",
      "       [ 0.02939469, -0.05690451]], dtype=float32))]\n",
      "updated vectors:  [array([[-0.0214479 , -0.0564855 ],\n",
      "       [ 0.11365304, -0.0784393 ]], dtype=float32), array([[-0.14075986,  0.10927075],\n",
      "       [-0.14075986,  0.10927075]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test_grads_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "Tensor(\"FixedUnigramCandidateSampler_6:0\", shape=(5,), dtype=int64)\n",
      "[2 0 4 1 3]\n"
     ]
    }
   ],
   "source": [
    "labels = tf.Variable([1,2])\n",
    "labels_matrix = tf.reshape(\n",
    "            tf.cast(labels,\n",
    "                    dtype=tf.int64),\n",
    "            [2, 1])\n",
    "\n",
    "# Negative sampling.\n",
    "sampled_ids, _, _ = (tf.nn.fixed_unigram_candidate_sampler(\n",
    "    true_classes=labels_matrix,\n",
    "    num_true=1,\n",
    "    num_sampled=5,\n",
    "    unique=True,  # set to True if all the samples need to be unique\n",
    "    range_max=5,\n",
    "    distortion=0.75,\n",
    "    unigrams=[1,1,1,1,1]))\n",
    "                     \n",
    "print(sampled_ids.shape)\n",
    "print(sampled_ids)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(sampled_ids))\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
